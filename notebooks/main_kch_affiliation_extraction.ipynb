{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Goals\n",
    "- To prepare a mini version of the data sources for extracting the affliation of the papers. That is, the origin of the papers' data, which we assume the data is collected from the regions/countries that the authors are from.\n",
    "- To identify the countries of the data origin for each paper. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get only the location information of each papers\n",
    "- None of the columns are unique id, including cord_uid. But, we will use this for now because it has the most unique ids. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(51078, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cord_uid</th>\n",
       "      <th>affiliations</th>\n",
       "      <th>location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>xqhn0vbp</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gi6uaa83</td>\n",
       "      <td>Todd R Disotell (New York University ; 25 Wave...</td>\n",
       "      <td>25 Waverly Place ; 10003 ; New York ; NY ; USA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>le0ogx1s</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fy4w7xz8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0qaoam29</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cord_uid                                       affiliations  \\\n",
       "0  xqhn0vbp                                                NaN   \n",
       "1  gi6uaa83  Todd R Disotell (New York University ; 25 Wave...   \n",
       "2  le0ogx1s                                                NaN   \n",
       "3  fy4w7xz8                                                NaN   \n",
       "4  0qaoam29                                                NaN   \n",
       "\n",
       "                                         location  \n",
       "0                                             NaN  \n",
       "1  25 Waverly Place ; 10003 ; New York ; NY ; USA  \n",
       "2                                             NaN  \n",
       "3                                             NaN  \n",
       "4                                             NaN  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the data columns and remove some reducdant information\n",
    "col_to_remove = ['text', 'bibliography']\n",
    "col_names = pd.read_csv('data/merged_raw_data.csv', nrows=1).columns.tolist()\n",
    "for c in col_to_remove:\n",
    "    col_names.remove(c)\n",
    "col_names = ['cord_uid', 'affiliations', 'location']\n",
    "\n",
    "# load the data\n",
    "df = pd.read_csv('data/merged_raw_data.csv', usecols=col_names)\n",
    "\n",
    "# check\n",
    "print(df.shape)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save\n",
    "df.to_csv('data/merged_raw_data_location.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the data and then identify their location\n",
    "- geograpy\n",
    "    - geograpy1 or 2 did not work because of the errors in installation: https://github.com/Corollarium/geograpy2 has installation issues. DID NOT USE IT\n",
    "    - geograpy3 works: https://github.com/jmbielec/geograpy3\n",
    "- can GeoText as well: https://github.com/elyase/geotext\n",
    "- look like the geograpy3 is more robust to bad text (although not 100% correct) that can detect more regions, but the precision may be low\n",
    "- may be we should combine both the use of geograpy and geotext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from geotext import GeoText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18558, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cord_uid</th>\n",
       "      <th>affiliations</th>\n",
       "      <th>location</th>\n",
       "      <th>affilation_extraction</th>\n",
       "      <th>location_extraction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gi6uaa83</td>\n",
       "      <td>Todd R Disotell (New York University ; 25 Wave...</td>\n",
       "      <td>25 Waverly Place ; 10003 ; New York ; NY ; USA</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1wswi7us</td>\n",
       "      <td>Yee Leng Yap ; Xue Wu Zhang ; Antoine Danchin ...</td>\n",
       "      <td>;   ; 75724, Cedex 15 ; Paris ; France</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>yy96yeu9</td>\n",
       "      <td>David Wang (University of California San Franc...</td>\n",
       "      <td>San Francisco ; California ; United States of ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cord_uid                                       affiliations  \\\n",
       "0  gi6uaa83  Todd R Disotell (New York University ; 25 Wave...   \n",
       "1  1wswi7us  Yee Leng Yap ; Xue Wu Zhang ; Antoine Danchin ...   \n",
       "2  yy96yeu9  David Wang (University of California San Franc...   \n",
       "\n",
       "                                            location  affilation_extraction  \\\n",
       "0     25 Waverly Place ; 10003 ; New York ; NY ; USA                      0   \n",
       "1             ;   ; 75724, Cedex 15 ; Paris ; France                      0   \n",
       "2  San Francisco ; California ; United States of ...                      0   \n",
       "\n",
       "   location_extraction  \n",
       "0                    0  \n",
       "1                    0  \n",
       "2                    0  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load data\n",
    "df = pd.read_csv('data/merged_raw_data_location.csv')\n",
    "df = df.drop(columns=['Unnamed: 0'])\n",
    "df = df.dropna()\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "# create fake columns\n",
    "df['affilation_extraction'] = 0\n",
    "df['location_extraction'] = 0\n",
    "\n",
    "# check\n",
    "print(df.shape)\n",
    "df.head(3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Todd R Disotell (New York University ; 25 Waverly Place ; 10003 ; New York ; NY ; USA)\n",
      "{'United States': ['New York', 'Todd'], 'Argentina': ['Todd']}\n",
      "OrderedDict([('US', 3)])\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'dsa' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-54-deef3d3a07e1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mplaces\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGeoText\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcountry_mentions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mplaces\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mdsa\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'dsa' is not defined"
     ]
    }
   ],
   "source": [
    "# loop through each address and make classification\n",
    "for i in range(0, df.shape[0]):\n",
    "    text = df.iloc[i]['affiliations']\n",
    "    print(text)\n",
    "    \n",
    "    # geograpy3 extraction\n",
    "    places = geograpy3.get_place_context(text = text)\n",
    "    print(places.country_cities)\n",
    "    \n",
    "    # GeoText extraction\n",
    "    places = GeoText(text).country_mentions\n",
    "    print(places)\n",
    "    dsa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Taiwan', 'Tamkang University', 'National Central University', 'Tamsui', 'Chen', 'Academia Sinica', 'Tien', 'Taipei']\n",
      "[('Taiwan', 4), ('Tien', 1), ('National Central University', 1), ('Tamkang University', 1), ('Tamsui', 1), ('Chen', 1), ('Academia Sinica', 1), ('Taipei', 1)]\n",
      "{'Taiwan': ['Taipei']}\n",
      "\n",
      "OrderedDict([('TW', 5), ('US', 1)])\n"
     ]
    }
   ],
   "source": [
    "import geograpy3\n",
    "text_input = \"Yin-Jing Tien (National Central University ; 32001 ; Tao-Yuan ; Taiwan) ; Yun-Shien Lee (33305 ; Tao-Yuan ; Taiwan) ; Han-Ming Wu (Tamkang University ; 25137 ; Tamsui ; Taiwan) ; Chun-Houh Chen (Academia Sinica ; 11529 ; Taipei ; Taiwan)\"\n",
    "places = geograpy3.get_place_context(text = text_input)\n",
    "\n",
    "print(places.countries)\n",
    "print(places.country_mentions)\n",
    "print(places.country_cities)\n",
    "print()\n",
    "\n",
    "places = GeoText(text_input).country_mentions\n",
    "print(places)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
