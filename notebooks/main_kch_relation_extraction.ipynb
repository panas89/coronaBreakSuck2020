{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Information Extraction\n",
    "- 06/28/30 Extract the entity relations related to covid-19\n",
    "    - Whether there is relationship or not\n",
    "    - If so, what kind, and how likely\n",
    "    - Use the openNRE to do so\n",
    "\n",
    "- Examples: \n",
    "    - Risk Factors\n",
    "        - “The two-way interaction between COVID-19 and diabetes mellitus sets up a vicious cycle wherein COVID-19 leads to worsening of dysglycemia and diabetes mellitus”\n",
    "            1.\tCovid-19 has relationship with diabetes. \n",
    "            2.\tCovid-19 worsen diabetes\n",
    "            3.\tDoes not indicate diabetes is a risk factor; but indicate covid-19 impact diabetes. \n",
    "    - Efficacy of therapeutics and interventions\n",
    "        - i. “Increasing eosinophils may be an indicator of COVID-19 improvement. The COVID-19 patients may benefit from sustained lopinavir use.”\n",
    "            1.\tlopinavir may be efficient for treating covid-19.\n",
    "            2.\tOpenNRE: “eosinophils” has part (P527)  “covid-19”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from tqdm import tqdm_notebook\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from covid.models.relation.extraction import RelationExtractor\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample Extraction\n",
    "- There are two model available: wiki80_bert_softmax or wiki80_cnn_softmax. The first one is better. The model is from the supervised relation extraction: http://opennre.thunlp.ai/#/sent_re. \n",
    "- We need to add an additiona NER classifier to classify interesting term relationship (in addition to our defined one)\n",
    "- Among all the relations, there are several relations that are interesting, e.g., \"has part (P527)\", \"part of (P361)\", \"said to be the same as\", etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initiate the extractor\n",
    "rextractor = RelationExtractor(\"../covid/models/paperclassifier/interest.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract\n",
    "text = 'Increasing eosinophils may be an indicator of COVID-19 improvement. The COVID-19 patients may benefit from sustained lopinavir use.'\n",
    "relation = rextractor.extract(text, 'eosinophils', 'COVID-19')\n",
    "print(relation)\n",
    "\n",
    "relation = rextractor.extract(text, 'WORDNOTINTEXT', 'COVID-19')\n",
    "print(relation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Paper relationship extraction\n",
    "- We can utilize the interest.yml to accelerate the search and relationship extraction\n",
    "- We will focus on the relationship of covid to a particular keyword"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from covid.models.relation.extraction import RelationExtractor\n",
    "\n",
    "covidre = RelationExtractor(km_path='../covid/models/paperclassifier/interest.yaml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the paper-classified information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/paperclassifier/classified_merged_covid.csv')\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Information extraction for each keyword"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relations = covidre.extract_all(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['relations'] = relations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('../data/paperclassifier/classified_merged_covid_relation.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze the relations\n",
    "- This is more like for setting up examples to better look at the data using declarative tool, i.e., altair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import altair as alt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "alt.data_transformers.disable_max_rows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data\n",
    "df_r = pd.read_csv('../data/paperclassifier/classified_merged_covid_relation.csv')\n",
    "df_r.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### An example of string modification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "# modify the relations columns to make it more readable\n",
    "# string to list\n",
    "rs = []\n",
    "for x in df_r['relations'].tolist():\n",
    "    if isinstance(x, str):\n",
    "        rx = ast.literal_eval(x)\n",
    "        \n",
    "        # create content string\n",
    "        ss = []\n",
    "        for c in rx:\n",
    "            s = \"%s('%s', %.3f)\"%(c[1],c[2][0],c[2][1])\n",
    "            ss.append(s)\n",
    "        rx = \", \".join(ss)\n",
    "    else:\n",
    "        rx = None\n",
    "    rs.append(rx)\n",
    "print(len(rs))\n",
    "rs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization\n",
    "\n",
    "As of 10/11/20, I am planning to generate multiple plots for user to visually understand what the relation data table represents. Here are couple of figure to be plotted\n",
    "\n",
    "1. (Not a plot) Filter the data\n",
    "    - Select meaningful relationship; filter the rest; may choose only a few interpretable relationship\n",
    "        - \"has part\" = \"part of\" = \"coronavirus is related to ...\"\n",
    "        - (10/27/20 ABORT) \"said to be the same as\" = \"instance of\" = \"corvonavirus is ...\"\n",
    "    - Choose the paper that is published after covid breakout, i.e., 2020 Feb\n",
    "2. Plot x along time by month (since covid breakout). X can be\n",
    "    - the number of a relationship (e.g., part of) with an entity (e.g., RNA)\n",
    "3. Plot the summary count of different relationships with respect to the entity. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import altair as alt\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview plot\n",
    "Plot the number of identified relationship along time\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# preprocess\n",
    "# ========================================\n",
    "\n",
    "# ---------- 1. only select the paper published after covid time in 2020 Feb\n",
    "df_r['publish_time'] = pd.to_datetime(df_r['publish_time'])\n",
    "df_p = df_r.loc[df_r['publish_time'] > '2020-02-01', :]\n",
    "df_p = df_p.drop(columns='Unnamed: 0')\n",
    "df_p.head()\n",
    "\n",
    "# ---------- 2. Reformulate the dataframe\n",
    "# a. use a unique keyterm and a unique relation as a row, along with the paper title, sha, publish time, location.\n",
    "# This mean that multiple rows can have the same paper title. \n",
    "# b. only keep the useful relations that make sense to readers. Rename the relation\n",
    "# parameters\n",
    "df_new = []\n",
    "# accept_relations = {'has part': 'is related to',\n",
    "#                     'part of': 'is related to',\n",
    "#                     'said to be the same as': 'is', \n",
    "#                     'instance of': 'is'}\n",
    "accept_relations = {'has part': 'is related to',\n",
    "                    'part of': 'is related to',}\n",
    "for i in range(0, df_p.shape[0]):\n",
    "    s = df_p.iloc[i,:]\n",
    "    \n",
    "    # basic info \n",
    "    sha = s['sha']\n",
    "    title = s['title']\n",
    "    publish_time = s['publish_time']\n",
    "    location = s['location']\n",
    "    \n",
    "    # extract relations\n",
    "    rs = s['relations']\n",
    "    if isinstance(rs, str):\n",
    "        rx = ast.literal_eval(rs)\n",
    "\n",
    "        # create content string\n",
    "        for c in rx:\n",
    "            if c[2][0] in accept_relations.keys():\n",
    "                content = [c[1], accept_relations[c[2][0]], c[2][1], sha, title, publish_time, location]\n",
    "                df_new.append(content)\n",
    "\n",
    "# create dataframe\n",
    "df_new = pd.DataFrame(df_new, columns=['keyword', 'relation', 'probability', 'sha',\n",
    "                                       'title', 'publish_time', 'location'])\n",
    "print(df_new.shape)\n",
    "df_new.head(5)\n",
    "\n",
    "# ========================================\n",
    "# Plotly plot\n",
    "# ========================================\n",
    "fig = px.scatter(df_new, x='publish_time', y='probability',\n",
    "                )\n",
    "fig.update_layout(\n",
    "    title='Strength of discovered relationship along paper publication month',\n",
    "    xaxis_title=\"Publish Time\",\n",
    "    yaxis_title=\"Strength\",\n",
    "    font=dict(\n",
    "        family=\"Courier New, monospace\",\n",
    "        size=18,\n",
    "    )\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Altair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # base plot\n",
    "# chart_col = alt.vconcat().configure_axis(\n",
    "#     labelFontSize=20,\n",
    "#     titleFontSize=20\n",
    "# ).configure_title(\n",
    "#     fontSize=20,\n",
    "# )\n",
    "\n",
    "# # plot\n",
    "# chart = alt.Chart(df_new).mark_circle(size=60).encode(\n",
    "#     x='publish_time',\n",
    "#     y='probability',\n",
    "#     color='relation'\n",
    "# ).properties(\n",
    "#         width=400,\n",
    "#         height=500,\n",
    "#         title='Strength of discovered relationship along paper publication month').interactive(0)\n",
    "# chart.encoding.y.title='Strength (Probability)'\n",
    "\n",
    "# chart_col &= chart\n",
    "# chart_col"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## keyword-specific plot\n",
    "- Choose a particular keyword\n",
    "- Each relation will have a line plot\n",
    "- Aggregated probability per month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =======================================================\n",
    "# Data Preparation \n",
    "# =======================================================\n",
    "# Define what keyword we are interested to see the trend\n",
    "kw = 'fever'\n",
    "relations = ['is related to']\n",
    "\n",
    "# create groups\n",
    "df_grps = []\n",
    "for relation in relations:\n",
    "    # sub-df\n",
    "    df_sg = df_new.loc[(df_new['keyword'] == kw) & (df_new['relation']==relation), :]\n",
    "\n",
    "    # aggregated data\n",
    "    grp = df_sg.groupby(df_sg['publish_time'].dt.strftime('%B'))['probability']\n",
    "    statistics = [grp.mean(), grp.std(), grp.sem(), grp.count()]\n",
    "    df_grp = pd.DataFrame(statistics).transpose()\n",
    "    df_grp.columns = ['proba_mean', 'proba_std', 'proba_stderr', 'n']\n",
    "    df_grp = df_grp.fillna(0)\n",
    "    \n",
    "    # new column\n",
    "    df_grp['publish_month'] = df_grp.index\n",
    "    df_grp['relation'] = relation\n",
    "    df_grp['proba_min'] = df_grp['proba_mean'] - df_grp['proba_stderr']\n",
    "    df_grp['proba_max'] = df_grp['proba_mean'] + df_grp['proba_stderr']\n",
    "    \n",
    "    # append\n",
    "    df_grps.append(df_grp)\n",
    "df_grps = pd.concat(df_grps)\n",
    "df_grps\n",
    "\n",
    "# =======================================================\n",
    "# Plotly\n",
    "# =======================================================\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "fig = go.Figure(data=go.Scatter(\n",
    "        x=df_grps['publish_month'],\n",
    "        y=df_grps['proba_mean'],\n",
    "        error_y=dict(\n",
    "            type='data', # value of error bar given in data coordinates\n",
    "            array=df_grps['proba_stderr'],\n",
    "            visible=True)\n",
    "    ))\n",
    "fig.update_layout(\n",
    "    yaxis=dict(range=[0, 1]),\n",
    "    title=\"coronavirus - '%s' relationship\" %kw,\n",
    "    xaxis_title=\"Month\",\n",
    "    yaxis_title=\"Strength\",\n",
    "    font=dict(\n",
    "        family=\"Courier New, monospace\",\n",
    "        size=18,\n",
    "    )\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Altair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chart_col = alt.vconcat().configure_axis(\n",
    "#     labelFontSize=20,\n",
    "#     titleFontSize=20\n",
    "# ).configure_title(\n",
    "#     fontSize=20,\n",
    "# ).configure_point(\n",
    "#     size=100\n",
    "# )\n",
    "\n",
    "# # plot\n",
    "# line = alt.Chart(df_grps).mark_line(point=True).encode(\n",
    "#     x='publish_month',\n",
    "#     y='proba_mean',\n",
    "#     color='relation',\n",
    "#     shape=alt.Shape('relation', scale=alt.Scale(range=['cross', 'circle', 'square', 'triangle-right', 'diamond'])),\n",
    "# ).properties(\n",
    "#     width=400,\n",
    "#     height=500,\n",
    "#     title=\"coronavirus - '%s' relationship\" %kw\n",
    "# )\n",
    "\n",
    "# # generate the error bars\n",
    "# errorbars = alt.Chart(df_grps).mark_errorbar().encode(\n",
    "#     x=\"publish_month\",\n",
    "#     y=\"proba_min:Q\",\n",
    "#     y2=\"proba_max:Q\",\n",
    "#     color='relation'\n",
    "# )\n",
    "# errorbars.encoding.x.title='Month'\n",
    "# errorbars.encoding.y.title='Strength'\n",
    "# chart_col &= (line + errorbars)\n",
    "\n",
    "# # rename axis title\n",
    "\n",
    "# # plot\n",
    "# chart_col"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get top keywords for each relationship "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relations = ['is related to', 'is']\n",
    "\n",
    "# loop\n",
    "for r in relations:\n",
    "    df_sg = df_new.loc[df_new['relation'] == r]\n",
    "    df_sg = df_sg.groupby('keyword')['probability'].mean().sort_values(ascending=False).to_frame()\n",
    "    df_sg.columns = ['strength']\n",
    "    \n",
    "    # print\n",
    "    print('The relationship is:', r)\n",
    "    print(df_sg.head(10))\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview plot for several interesting keyword relationship\n",
    "- Look at the strength of the relationship along time\n",
    "- https://altair-viz.github.io/gallery/natural_disasters.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =======================================================\n",
    "# Data Preparation \n",
    "# =======================================================\n",
    "kw_interest = ['sore throat', 'fatigue', 'fever', 'upper respiratory infection', 'lung capacity',\n",
    "              'hospitalization', 'dry cough', 'sneezing', 'death', 'shortness of breath']\n",
    "df_new_p = df_new.copy()\n",
    "df_new_p = df_new_p[df_new_p['keyword'].isin(kw_interest)]\n",
    "df_new_p.head()\n",
    "\n",
    "# =======================================================\n",
    "# Plotly plot\n",
    "# =======================================================\n",
    "import plotly.express as px\n",
    "df = px.data.iris()\n",
    "fig = px.scatter(df_new_p, x=\"publish_time\", y=\"probability\", color=\"keyword\",\n",
    "                 size='probability')\n",
    "fig.update_layout(\n",
    "    yaxis=dict(range=[0, 1.1]),\n",
    "    title=\"coronavirus - keyword relationship\",\n",
    "    xaxis_title=\"Publish Time\",\n",
    "    yaxis_title=\"Strength\",\n",
    "    font=dict(\n",
    "        family=\"Courier New, monospace\",\n",
    "        size=18,\n",
    "    )\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Altair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kw_interest = ['sore throat', 'fatigue', 'fever', 'upper respiratory infection', 'lung capacity',\n",
    "#               'hospitalization', 'dry cough', 'sneezing', 'death', 'shortness of breath']\n",
    "# df_new_p = df_new.copy()\n",
    "# df_new_p = df_new_p[df_new_p['keyword'].isin(kw_interest)]\n",
    "\n",
    "# # base plot\n",
    "# chart_col = alt.vconcat().configure_axis(\n",
    "#     labelFontSize=14,\n",
    "#     titleFontSize=14\n",
    "# ).configure_title(\n",
    "#     fontSize=20,\n",
    "# )\n",
    "\n",
    "# # plot\n",
    "# chart = alt.Chart(df_new_p).mark_circle(\n",
    "#     opacity=0.8,\n",
    "#     stroke='black',\n",
    "#     strokeWidth=1\n",
    "# ).encode(\n",
    "#     alt.X('publish_time'),\n",
    "#     alt.Y('keyword'),\n",
    "#     alt.Size('probability:Q',\n",
    "#         scale=alt.Scale(range=[50, 200]),\n",
    "#         legend=alt.Legend(title='Strength')\n",
    "#     ),\n",
    "# ).properties(\n",
    "#     width=450,\n",
    "#     height=320\n",
    "# )\n",
    "# chart.encoding.x.title='Month'\n",
    "# chart.encoding.y.title='Entity'\n",
    "\n",
    "# # plot\n",
    "# chart_col &= chart\n",
    "# chart_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
